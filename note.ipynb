{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build uNet model\n",
    "# from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def conv_block(inputs, num_filters):\n",
    "#     x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "\n",
    "#     x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "# def encoder_block(inputs, num_filters):\n",
    "#     x = conv_block(inputs, num_filters)\n",
    "#     p = MaxPool2D((2, 2))(x)\n",
    "#     return x, p\n",
    "\n",
    "# def decoder_block(inputs, skip_features, num_filters):\n",
    "#     x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n",
    "#     x = Concatenate()([x, skip_features])\n",
    "#     x = conv_block(x, num_filters)\n",
    "#     return x\n",
    "\n",
    "# def build_unet(input_shape):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     s1, p1 = encoder_block(inputs, 64)\n",
    "#     s2, p2 = encoder_block(p1, 128)\n",
    "#     s3, p3 = encoder_block(p2, 256)\n",
    "#     # s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "#     # print(s1.shape, s2.shape, s3.shape, s4.shape)\n",
    "#     # print(p1.shape, p2.shape, p3.shape, p4.shape)\n",
    "    \n",
    "#     b1 = conv_block(p3, 512)\n",
    "\n",
    "#     # d1 = decoder_block(b1, s4, 512)\n",
    "#     d2 = decoder_block(b1, s3, 256)\n",
    "#     d3 = decoder_block(d2, s2, 128)\n",
    "#     d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "#     outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "#     model = Model(inputs, outputs, name=\"UNET\")\n",
    "#     return model\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     input_shape = (256, 256, 3)\n",
    "#     model = build_unet(input_shape)\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"UNet-MobileNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 128, 128, 32  864         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 32  128         ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 128, 128, 32  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1 (DepthwiseConv2D)    (None, 128, 128, 32  288         ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_bn (BatchNormalizati  (None, 128, 128, 32  128        ['conv_dw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_relu (ReLU)          (None, 128, 128, 32  0           ['conv_dw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1 (Conv2D)             (None, 128, 128, 64  2048        ['conv_dw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_bn (BatchNormalizati  (None, 128, 128, 64  256        ['conv_pw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_relu (ReLU)          (None, 128, 128, 64  0           ['conv_pw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pad_2 (ZeroPadding2D)     (None, 129, 129, 64  0           ['conv_pw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_2 (DepthwiseConv2D)    (None, 64, 64, 64)   576         ['conv_pad_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_2_bn (BatchNormalizati  (None, 64, 64, 64)  256         ['conv_dw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_2_relu (ReLU)          (None, 64, 64, 64)   0           ['conv_dw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_2 (Conv2D)             (None, 64, 64, 128)  8192        ['conv_dw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_2_bn (BatchNormalizati  (None, 64, 64, 128)  512        ['conv_pw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_2_relu (ReLU)          (None, 64, 64, 128)  0           ['conv_pw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_3 (DepthwiseConv2D)    (None, 64, 64, 128)  1152        ['conv_pw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_3_bn (BatchNormalizati  (None, 64, 64, 128)  512        ['conv_dw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_3_relu (ReLU)          (None, 64, 64, 128)  0           ['conv_dw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_3 (Conv2D)             (None, 64, 64, 128)  16384       ['conv_dw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_3_bn (BatchNormalizati  (None, 64, 64, 128)  512        ['conv_pw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_3_relu (ReLU)          (None, 64, 64, 128)  0           ['conv_pw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_4 (ZeroPadding2D)     (None, 65, 65, 128)  0           ['conv_pw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_4 (DepthwiseConv2D)    (None, 32, 32, 128)  1152        ['conv_pad_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_4_bn (BatchNormalizati  (None, 32, 32, 128)  512        ['conv_dw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_4_relu (ReLU)          (None, 32, 32, 128)  0           ['conv_dw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_4 (Conv2D)             (None, 32, 32, 256)  32768       ['conv_dw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_4_bn (BatchNormalizati  (None, 32, 32, 256)  1024       ['conv_pw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_4_relu (ReLU)          (None, 32, 32, 256)  0           ['conv_pw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_5 (DepthwiseConv2D)    (None, 32, 32, 256)  2304        ['conv_pw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_5_bn (BatchNormalizati  (None, 32, 32, 256)  1024       ['conv_dw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_5_relu (ReLU)          (None, 32, 32, 256)  0           ['conv_dw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_5 (Conv2D)             (None, 32, 32, 256)  65536       ['conv_dw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_5_bn (BatchNormalizati  (None, 32, 32, 256)  1024       ['conv_pw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_5_relu (ReLU)          (None, 32, 32, 256)  0           ['conv_pw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_6 (ZeroPadding2D)     (None, 33, 33, 256)  0           ['conv_pw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_6 (DepthwiseConv2D)    (None, 16, 16, 256)  2304        ['conv_pad_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_6_bn (BatchNormalizati  (None, 16, 16, 256)  1024       ['conv_dw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_6_relu (ReLU)          (None, 16, 16, 256)  0           ['conv_dw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_6 (Conv2D)             (None, 16, 16, 512)  131072      ['conv_dw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_6_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_pw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_6_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_pw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_7 (DepthwiseConv2D)    (None, 16, 16, 512)  4608        ['conv_pw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_7_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_dw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_7_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_dw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_7 (Conv2D)             (None, 16, 16, 512)  262144      ['conv_dw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_7_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_pw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_7_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_pw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_8 (DepthwiseConv2D)    (None, 16, 16, 512)  4608        ['conv_pw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_8_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_dw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_8_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_dw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_8 (Conv2D)             (None, 16, 16, 512)  262144      ['conv_dw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_8_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_pw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_8_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_pw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_9 (DepthwiseConv2D)    (None, 16, 16, 512)  4608        ['conv_pw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_9_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_dw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_9_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_dw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_9 (Conv2D)             (None, 16, 16, 512)  262144      ['conv_dw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_9_bn (BatchNormalizati  (None, 16, 16, 512)  2048       ['conv_pw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_9_relu (ReLU)          (None, 16, 16, 512)  0           ['conv_pw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_10 (DepthwiseConv2D)   (None, 16, 16, 512)  4608        ['conv_pw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_10_bn (BatchNormalizat  (None, 16, 16, 512)  2048       ['conv_dw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_10_relu (ReLU)         (None, 16, 16, 512)  0           ['conv_dw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_10 (Conv2D)            (None, 16, 16, 512)  262144      ['conv_dw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_10_bn (BatchNormalizat  (None, 16, 16, 512)  2048       ['conv_pw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_10_relu (ReLU)         (None, 16, 16, 512)  0           ['conv_pw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_11 (DepthwiseConv2D)   (None, 16, 16, 512)  4608        ['conv_pw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_11_bn (BatchNormalizat  (None, 16, 16, 512)  2048       ['conv_dw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_11_relu (ReLU)         (None, 16, 16, 512)  0           ['conv_dw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_11 (Conv2D)            (None, 16, 16, 512)  262144      ['conv_dw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_11_bn (BatchNormalizat  (None, 16, 16, 512)  2048       ['conv_pw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_11_relu (ReLU)         (None, 16, 16, 512)  0           ['conv_pw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 256)  1179904    ['conv_pw_11_relu[0][0]']        \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'conv_pw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 256)  1179904     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 128)  295040     ['activation_4[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                                                  'conv_pw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 128)  295040      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 64  73792      ['activation_5[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_6[0][0]',     \n",
      "                                8)                                'conv_pw_1_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 64  73792       ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 128, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 32  18464      ['activation_6[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d_transpose_7[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 32  128        ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 256, 256, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 1)  33          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,754,977\n",
      "Trainable params: 4,739,297\n",
      "Non-trainable params: 15,680\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, BatchNormalization, Activation\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def unet_mobilenet(input_shape=(512, 512, 3), num_classes=1):\n",
    "    \"\"\"\n",
    "    UNet model with MobileNet as the encoder backbone.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input image (height, width, channels).\n",
    "        num_classes (int): Number of output classes for segmentation.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: UNet model with MobileNet backbone.\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    mobilenet = MobileNet(input_tensor=inputs, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    skip1 = mobilenet.get_layer(\"conv_pw_1_relu\").output  \n",
    "    skip2 = mobilenet.get_layer(\"conv_pw_3_relu\").output \n",
    "    skip3 = mobilenet.get_layer(\"conv_pw_5_relu\").output \n",
    "    bottleneck = mobilenet.get_layer(\"conv_pw_11_relu\").output  \n",
    "\n",
    "    # Decoder: Up-sampling and concatenation\n",
    "    up1 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(bottleneck)\n",
    "    up1 = concatenate([up1, skip3])\n",
    "    up1 = Conv2D(256, (3, 3), padding=\"same\")(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation(\"relu\")(up1)\n",
    "\n",
    "    up2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(up1)\n",
    "    up2 = concatenate([up2, skip2])\n",
    "    up2 = Conv2D(128, (3, 3), padding=\"same\")(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation(\"relu\")(up2)\n",
    "\n",
    "    up3 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(up2)\n",
    "    up3 = concatenate([up3, skip1])\n",
    "    up3 = Conv2D(64, (3, 3), padding=\"same\")(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation(\"relu\")(up3)\n",
    "\n",
    "    up4 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"same\")(up3)\n",
    "    up4 = Conv2D(32, (3, 3), padding=\"same\")(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation(\"relu\")(up4)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"sigmoid\")(up4)\n",
    "    model = Model(inputs, outputs, name=\"UNet-MobileNet\")\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1\n",
    "model = unet_mobilenet(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Smoothing factor to avoid division by zero\n",
    "smooth = 1e-15\n",
    "\n",
    "# Dice Coefficient\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Intersection over Union (IoU)\n",
    "def iou(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Precision\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    predicted_positives = tf.reduce_sum(y_pred)\n",
    "    return (true_positives + smooth) / (predicted_positives + smooth)\n",
    "\n",
    "# Recall\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    return (true_positives + smooth) / (possible_positives + smooth)\n",
    "\n",
    "# F1 Score\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return (2. * prec * rec + smooth) / (prec + rec + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1840 - 1840\n",
      "Valid: 612 - 612\n",
      "Test : 612 - 612\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.7801 - dice_coef: 0.2199\n",
      "Epoch 1: val_loss improved from inf to 0.67992, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 71ms/step - loss: 0.7801 - dice_coef: 0.2199 - val_loss: 0.6799 - val_dice_coef: 0.3201 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.5713 - dice_coef: 0.4287\n",
      "Epoch 2: val_loss improved from 0.67992 to 0.51271, saving model to files\\model.h5\n",
      "460/460 [==============================] - 33s 71ms/step - loss: 0.5713 - dice_coef: 0.4287 - val_loss: 0.5127 - val_dice_coef: 0.4873 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.3831 - dice_coef: 0.6169\n",
      "Epoch 3: val_loss improved from 0.51271 to 0.36164, saving model to files\\model.h5\n",
      "460/460 [==============================] - 33s 72ms/step - loss: 0.3831 - dice_coef: 0.6169 - val_loss: 0.3616 - val_dice_coef: 0.6384 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.2532 - dice_coef: 0.7468\n",
      "Epoch 4: val_loss improved from 0.36164 to 0.29763, saving model to files\\model.h5\n",
      "460/460 [==============================] - 33s 72ms/step - loss: 0.2532 - dice_coef: 0.7468 - val_loss: 0.2976 - val_dice_coef: 0.7024 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1830 - dice_coef: 0.8170\n",
      "Epoch 5: val_loss improved from 0.29763 to 0.24356, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.1830 - dice_coef: 0.8170 - val_loss: 0.2436 - val_dice_coef: 0.7564 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1452 - dice_coef: 0.8548\n",
      "Epoch 6: val_loss improved from 0.24356 to 0.23177, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.1452 - dice_coef: 0.8548 - val_loss: 0.2318 - val_dice_coef: 0.7682 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1222 - dice_coef: 0.8778\n",
      "Epoch 7: val_loss did not improve from 0.23177\n",
      "460/460 [==============================] - 33s 72ms/step - loss: 0.1222 - dice_coef: 0.8778 - val_loss: 0.2321 - val_dice_coef: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1059 - dice_coef: 0.8941\n",
      "Epoch 8: val_loss improved from 0.23177 to 0.21109, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.1059 - dice_coef: 0.8941 - val_loss: 0.2111 - val_dice_coef: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0930 - dice_coef: 0.9070\n",
      "Epoch 9: val_loss improved from 0.21109 to 0.20593, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.0930 - dice_coef: 0.9070 - val_loss: 0.2059 - val_dice_coef: 0.7941 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0847 - dice_coef: 0.9153\n",
      "Epoch 10: val_loss improved from 0.20593 to 0.20142, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.0847 - dice_coef: 0.9153 - val_loss: 0.2014 - val_dice_coef: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0741 - dice_coef: 0.9259\n",
      "Epoch 11: val_loss improved from 0.20142 to 0.19300, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.0741 - dice_coef: 0.9259 - val_loss: 0.1930 - val_dice_coef: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0691 - dice_coef: 0.9309\n",
      "Epoch 12: val_loss did not improve from 0.19300\n",
      "460/460 [==============================] - 33s 73ms/step - loss: 0.0691 - dice_coef: 0.9309 - val_loss: 0.2044 - val_dice_coef: 0.7956 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0717 - dice_coef: 0.9283\n",
      "Epoch 13: val_loss improved from 0.19300 to 0.19220, saving model to files\\model.h5\n",
      "460/460 [==============================] - 34s 73ms/step - loss: 0.0717 - dice_coef: 0.9283 - val_loss: 0.1922 - val_dice_coef: 0.8078 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0662 - dice_coef: 0.9338\n",
      "Epoch 14: val_loss did not improve from 0.19220\n",
      "460/460 [==============================] - 33s 73ms/step - loss: 0.0662 - dice_coef: 0.9338 - val_loss: 0.1995 - val_dice_coef: 0.8005 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0630 - dice_coef: 0.9370\n",
      "Epoch 15: val_loss did not improve from 0.19220\n",
      "460/460 [==============================] - 35s 75ms/step - loss: 0.0630 - dice_coef: 0.9370 - val_loss: 0.1932 - val_dice_coef: 0.8068 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0587 - dice_coef: 0.9413\n",
      "Epoch 16: val_loss did not improve from 0.19220\n",
      "460/460 [==============================] - 34s 75ms/step - loss: 0.0587 - dice_coef: 0.9413 - val_loss: 0.1978 - val_dice_coef: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0576 - dice_coef: 0.9424\n",
      "Epoch 17: val_loss did not improve from 0.19220\n",
      "460/460 [==============================] - 34s 75ms/step - loss: 0.0576 - dice_coef: 0.9424 - val_loss: 0.1930 - val_dice_coef: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0582 - dice_coef: 0.9418\n",
      "Epoch 18: val_loss did not improve from 0.19220\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "460/460 [==============================] - 35s 75ms/step - loss: 0.0582 - dice_coef: 0.9418 - val_loss: 0.1942 - val_dice_coef: 0.8058 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0522 - dice_coef: 0.9478\n",
      "Epoch 19: val_loss improved from 0.19220 to 0.18992, saving model to files\\model.h5\n",
      "460/460 [==============================] - 35s 76ms/step - loss: 0.0522 - dice_coef: 0.9478 - val_loss: 0.1899 - val_dice_coef: 0.8101 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0472 - dice_coef: 0.9528\n",
      "Epoch 20: val_loss improved from 0.18992 to 0.18851, saving model to files\\model.h5\n",
      "460/460 [==============================] - 35s 77ms/step - loss: 0.0472 - dice_coef: 0.9528 - val_loss: 0.1885 - val_dice_coef: 0.8115 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0442 - dice_coef: 0.9558\n",
      "Epoch 21: val_loss improved from 0.18851 to 0.18807, saving model to files\\model.h5\n",
      "460/460 [==============================] - 45s 97ms/step - loss: 0.0442 - dice_coef: 0.9558 - val_loss: 0.1881 - val_dice_coef: 0.8119 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0417 - dice_coef: 0.9583\n",
      "Epoch 22: val_loss improved from 0.18807 to 0.18781, saving model to files\\model.h5\n",
      "460/460 [==============================] - 46s 99ms/step - loss: 0.0417 - dice_coef: 0.9583 - val_loss: 0.1878 - val_dice_coef: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0397 - dice_coef: 0.9603\n",
      "Epoch 23: val_loss did not improve from 0.18781\n",
      "460/460 [==============================] - 35s 75ms/step - loss: 0.0397 - dice_coef: 0.9603 - val_loss: 0.1878 - val_dice_coef: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0378 - dice_coef: 0.9622\n",
      "Epoch 24: val_loss did not improve from 0.18781\n",
      "460/460 [==============================] - 42s 91ms/step - loss: 0.0378 - dice_coef: 0.9622 - val_loss: 0.1882 - val_dice_coef: 0.8118 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0363 - dice_coef: 0.9637\n",
      "Epoch 25: val_loss did not improve from 0.18781\n",
      "460/460 [==============================] - 44s 96ms/step - loss: 0.0363 - dice_coef: 0.9637 - val_loss: 0.1884 - val_dice_coef: 0.8116 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0348 - dice_coef: 0.9652\n",
      "Epoch 26: val_loss did not improve from 0.18781\n",
      "460/460 [==============================] - 40s 87ms/step - loss: 0.0348 - dice_coef: 0.9652 - val_loss: 0.1882 - val_dice_coef: 0.8118 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0336 - dice_coef: 0.9664\n",
      "Epoch 27: val_loss did not improve from 0.18781\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "460/460 [==============================] - 40s 87ms/step - loss: 0.0336 - dice_coef: 0.9664 - val_loss: 0.1887 - val_dice_coef: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0329 - dice_coef: 0.9671\n",
      "Epoch 28: val_loss improved from 0.18781 to 0.18780, saving model to files\\model.h5\n",
      "460/460 [==============================] - 41s 90ms/step - loss: 0.0329 - dice_coef: 0.9671 - val_loss: 0.1878 - val_dice_coef: 0.8122 - lr: 1.0000e-06\n",
      "Epoch 29/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0326 - dice_coef: 0.9674\n",
      "Epoch 29: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 41s 90ms/step - loss: 0.0326 - dice_coef: 0.9674 - val_loss: 0.1879 - val_dice_coef: 0.8121 - lr: 1.0000e-06\n",
      "Epoch 30/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0323 - dice_coef: 0.9677\n",
      "Epoch 30: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 40s 87ms/step - loss: 0.0323 - dice_coef: 0.9677 - val_loss: 0.1880 - val_dice_coef: 0.8120 - lr: 1.0000e-06\n",
      "Epoch 31/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0321 - dice_coef: 0.9679\n",
      "Epoch 31: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 39s 85ms/step - loss: 0.0321 - dice_coef: 0.9679 - val_loss: 0.1881 - val_dice_coef: 0.8119 - lr: 1.0000e-06\n",
      "Epoch 32/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0319 - dice_coef: 0.9681\n",
      "Epoch 32: val_loss did not improve from 0.18780\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "460/460 [==============================] - 41s 89ms/step - loss: 0.0319 - dice_coef: 0.9681 - val_loss: 0.1882 - val_dice_coef: 0.8118 - lr: 1.0000e-06\n",
      "Epoch 33/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0320 - dice_coef: 0.9680\n",
      "Epoch 33: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 44s 95ms/step - loss: 0.0320 - dice_coef: 0.9680 - val_loss: 0.1889 - val_dice_coef: 0.8111 - lr: 1.0000e-07\n",
      "Epoch 34/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0318 - dice_coef: 0.9682\n",
      "Epoch 34: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 44s 96ms/step - loss: 0.0318 - dice_coef: 0.9682 - val_loss: 0.1891 - val_dice_coef: 0.8109 - lr: 1.0000e-07\n",
      "Epoch 35/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0318 - dice_coef: 0.9682\n",
      "Epoch 35: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 41s 88ms/step - loss: 0.0318 - dice_coef: 0.9682 - val_loss: 0.1892 - val_dice_coef: 0.8108 - lr: 1.0000e-07\n",
      "Epoch 36/200\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.0318 - dice_coef: 0.9682\n",
      "Epoch 36: val_loss did not improve from 0.18780\n",
      "460/460 [==============================] - 40s 86ms/step - loss: 0.0318 - dice_coef: 0.9682 - val_loss: 0.1892 - val_dice_coef: 0.8108 - lr: 1.0000e-07\n",
      "Epoch 37/200\n",
      " 21/460 [>.............................] - ETA: 31s - loss: 0.0322 - dice_coef: 0.9678"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\" Global parameters \"\"\"\n",
    "H = 256\n",
    "W = 256\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path, split=0.2):\n",
    "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
    "    x = cv2.resize(x, (W, H))   ## (h, w)\n",
    "    x = x / 255.0              \n",
    "    x = x.astype(np.float32)  \n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 4\n",
    "    lr = 1e-4\n",
    "    num_epochs = 200\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"./DATASET/\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test : {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    \"\"\"Model\"\"\"\n",
    "    model = unet_mobilenet((H, W, 3))\n",
    "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function: iou. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Load the model \"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdice_coef\u001b[39m\u001b[38;5;124m\"\u001b[39m: dice_coef, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdice_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: dice_loss}):\n\u001b[1;32m---> 46\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Dataset \"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./DATASET/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fitsu\\miniconda3\\envs\\gpu_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\fitsu\\miniconda3\\envs\\gpu_tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:769\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    767\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure this object is passed to the `custom_objects` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    775\u001b[0m         )\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown metric function: iou. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\" Global parameters \"\"\"\n",
    "H = 256\n",
    "W = 256\n",
    "\n",
    "\"\"\" Creating a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def save_results(image, mask, y_pred, save_image_path):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
    "    y_pred = y_pred * 255\n",
    "\n",
    "    line = np.ones((H, 10, 3)) * 255\n",
    "\n",
    "    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"results\")\n",
    "\n",
    "    \"\"\" Load the model \"\"\"\n",
    "    with CustomObjectScope({\"dice_coef\": dice_coef, \"dice_loss\": dice_loss}):\n",
    "        model = tf.keras.models.load_model(os.path.join(\"files\", \"model.h5\"))\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"./DATASET/\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    \"\"\" Prediction and Evaluation \"\"\"\n",
    "    SCORE = []\n",
    "    for x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[-1]\n",
    "\n",
    "        \"\"\" Reading the image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n",
    "        image = cv2.resize(image, (W, H))       ## [H, w, 3]\n",
    "        x = image/255.0                         ## [H, w, 3]\n",
    "        x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n",
    "\n",
    "        \"\"\" Reading the mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (W, H))\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "        y_pred = model.predict(x, verbose=0)[0]\n",
    "        y_pred = np.squeeze(y_pred, axis=-1)\n",
    "        y_pred = y_pred >= 0.5\n",
    "        y_pred = y_pred.astype(np.int32)\n",
    "\n",
    "        \"\"\" Saving the prediction \"\"\"\n",
    "        save_image_path = os.path.join(\"results\", name)\n",
    "        save_results(image, mask, y_pred, save_image_path)\n",
    "\n",
    "        \"\"\" Flatten the array \"\"\"\n",
    "        mask = mask/255.0\n",
    "        mask = (mask > 0.5).astype(np.int32).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "\n",
    "        \"\"\" Calculating the metrics values \"\"\"\n",
    "        f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
    "        precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
    "        SCORE.append([name, f1_value, jac_value, recall_value, precision_value])\n",
    "\n",
    "    \"\"\" Metrics values \"\"\"\n",
    "    score = [s[1:]for s in SCORE]\n",
    "    score = np.mean(score, axis=0)\n",
    "    print(f\"F1: {score[0]:0.5f}\")\n",
    "    print(f\"Jaccard: {score[1]:0.5f}\")\n",
    "    print(f\"Recall: {score[2]:0.5f}\")\n",
    "    print(f\"Precision: {score[3]:0.5f}\")\n",
    "\n",
    "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
    "    df.to_csv(\"files/score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
